#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#
# Copyright (c) 2024 Emasoft
#
# This software is licensed under the MIT License.
# Refer to the LICENSE file for more details.

import argparse
import tempfile
from pathlib import Path
import sys
from typing import List, Dict, Any, Optional # Added Optional

# Prefect integration (optional, can be made truly optional later)
try:
    from prefect import task, flow
    PREFECT_AVAILABLE = True
except ImportError:
    PREFECT_AVAILABLE = False
    # Define dummy decorators if Prefect is not available
    def task(fn=None, **kwargs):
        if fn:
            return fn
        def decorator(fn_deco):
            return fn_deco
        return decorator
    def flow(fn=None, **kwargs):
        if fn:
            return fn
        def decorator(fn_deco):
            return fn_deco
        return decorator

# Local module imports
from file_system_operations import (
    scan_directory_for_occurrences,
    save_transactions,
    load_transactions,
    execute_all_transactions,
    TransactionStatus, # For self-test verification
    TransactionType, # For self-test verification
    TRANSACTION_FILE_BACKUP_EXT # Import for constructing backup filenames
)
# from replace_logic import replace_flojoy_occurrences # Not directly used by main, but by file_system_operations

# --- Constants ---
# These are now defined in file_system_operations, but main script might need its own names for files
MAIN_TRANSACTION_FILE_NAME = "planned_transactions.json" 
# Validation transaction file might be removed if dual scan for determinism is simplified/removed
# For now, let's assume it's not strictly needed by the new core logic, but self-test might use it.
SELF_TEST_PRIMARY_TRANSACTION_FILE = "self_test_transactions.json"


# --- Self-Test Functionality ---
def _create_self_test_environment(base_dir: Path) -> None:
    """Creates a directory structure and files for self-testing."""
    # Simplified for the new "flojoy" -> "atlasvibe" focus
    (base_dir / "flojoy_root" / "sub_flojoy_folder" / "another_FLOJOY_dir").mkdir(parents=True, exist_ok=True)
    (base_dir / "flojoy_root" / "sub_flojoy_folder" / "another_FLOJOY_dir" / "deep_flojoy_file.txt").write_text(
        "Line 1: flojoy content.\nLine 2: More Flojoy here.\nLine 3: No target.\nLine 4: FLOJOY project."
    )
    (base_dir / "flojoy_root" / "another_flojoy_file.py").write_text(
        "import flojoy_lib\n# class MyFlojoyClass: pass"
    )
    (base_dir / "only_name_flojoy.md").write_text("Content without target string.")
    (base_dir / "file_with_floJoy_lines.txt").write_text(
        "First floJoy.\nSecond FloJoy.\nflojoy and FLOJOY on same line."
    )
    (base_dir / "exclude_this_flojoy_file.txt").write_text("flojoy content in excluded file")
    (base_dir / "no_target_here.log").write_text("This is a log file without the target string.")


@task
def _verify_self_test_results_task(
    temp_dir: Path,
    original_transaction_file: Path # Path to the JSON file generated by the scan
) -> bool:
    print("--- Verifying Self-Test Results ---")
    passed_checks = 0
    failed_checks = 0

    def check(condition: bool, pass_msg: str, fail_msg: str) -> None:
        nonlocal passed_checks, failed_checks
        if condition:
            print(f"PASS: {pass_msg}")
            passed_checks += 1
        else:
            print(f"FAIL: {fail_msg}")
            failed_checks += 1

    # 1. Verify structural renames (based on expected final paths)
    # Expected paths after "flojoy" -> "atlasvibe" transformation
    exp_paths_after_rename = {
        "atlasvibe_root": temp_dir / "atlasvibe_root",
        "sub_atlasvibe_folder": temp_dir / "atlasvibe_root" / "sub_atlasvibe_folder",
        "another_ATLASVIBE_dir": temp_dir / "atlasvibe_root" / "sub_atlasvibe_folder" / "another_ATLASVIBE_dir",
        "deep_atlasvibe_file.txt": temp_dir / "atlasvibe_root" / "sub_atlasvibe_folder" / "another_ATLASVIBE_dir" / "deep_atlasvibe_file.txt",
        "another_atlasvibe_file.py": temp_dir / "atlasvibe_root" / "another_atlasvibe_file.py",
        "only_name_atlasvibe.md": temp_dir / "only_name_atlasvibe.md",
        "file_with_atlasVibe_lines.txt": temp_dir / "file_with_atlasVibe_lines.txt", # floJoy -> atlasVibe
        "no_target_here.log": temp_dir / "no_target_here.log", # Unchanged name
        "exclude_this_flojoy_file.txt": temp_dir / "exclude_this_flojoy_file.txt" # Excluded, so original name
    }

    for name, path in exp_paths_after_rename.items():
        check(path.exists(), f"Path '{path.relative_to(temp_dir)}' exists for '{name}'.",
              f"Path '{path.relative_to(temp_dir)}' MISSING for '{name}'.")

    check(not (temp_dir / "flojoy_root").exists(), "Old 'flojoy_root' base directory removed.",
          "Old 'flojoy_root' base directory STILL EXISTS.")

    # 2. Verify content changes for specific files
    # deep_atlasvibe_file.txt
    deep_file = exp_paths_after_rename.get("deep_atlasvibe_file.txt")
    if deep_file and deep_file.exists():
        content = deep_file.read_text(encoding='utf-8')
        expected_content = "Line 1: atlasvibe content.\nLine 2: More AtlasVibe here.\nLine 3: No target.\nLine 4: ATLASVIBE project."
        check(content == expected_content, "Content of 'deep_atlasvibe_file.txt' correct.",
              f"Content of 'deep_atlasvibe_file.txt' INCORRECT. Got:\n{content}\nExpected:\n{expected_content}")

    # file_with_atlasVibe_lines.txt
    multi_line_file = exp_paths_after_rename.get("file_with_atlasVibe_lines.txt")
    if multi_line_file and multi_line_file.exists():
        content = multi_line_file.read_text(encoding='utf-8')
        expected_content = "First atlasVibe.\nSecond AtlasVibe.\natlasvibe and ATLASVIBE on same line."
        check(content == expected_content, "Content of 'file_with_atlasVibe_lines.txt' correct.",
              f"Content of 'file_with_atlasVibe_lines.txt' INCORRECT. Got:\n{content}\nExpected:\n{expected_content}")

    # only_name_atlasvibe.md (content should be unchanged)
    only_name_file = exp_paths_after_rename.get("only_name_atlasvibe.md")
    if only_name_file and only_name_file.exists():
        content = only_name_file.read_text(encoding='utf-8')
        expected_content = "Content without target string."
        check(content == expected_content, "Content of 'only_name_atlasvibe.md' (name-only change) correct.",
              "Content of 'only_name_atlasvibe.md' (name-only change) INCORRECT.")

    # excluded_file (name and content should be unchanged)
    excluded_file = exp_paths_after_rename.get("exclude_this_flojoy_file.txt")
    if excluded_file and excluded_file.exists(): # Should exist with original name
        content = excluded_file.read_text(encoding='utf-8')
        expected_content = "flojoy content in excluded file"
        check(content == expected_content, "Content of excluded file correct.",
              "Content of excluded file INCORRECT.")
    else: # This check is covered by path checks, but good to be explicit if path check fails
        if not (temp_dir / "exclude_this_flojoy_file.txt").exists():
             check(False, "", "Excluded file 'exclude_this_flojoy_file.txt' MISSING.")


    # 3. Verify transaction statuses in the JSON file
    transactions = load_transactions(original_transaction_file)
    if transactions:
        all_completed_or_skipped = True
        for tx in transactions:
            # Excluded files should not generate transactions or they should be SKIPPED if they did
            if "exclude_this_flojoy_file.txt" in tx["PATH"]:
                if tx["STATUS"] != TransactionStatus.SKIPPED.value and tx["STATUS"] != TransactionStatus.PENDING.value : # PENDING if scan doesn't mark excluded as skipped
                    # This depends on whether excluded files are filtered out before transaction creation or marked as skipped
                    # For now, assume they might be PENDING if not processed, or SKIPPED if filtered by execution logic
                    # A stricter test would ensure no transaction is created for them.
                    # For now, let's assume they are correctly skipped by execution if they were part of `excluded_files` list.
                    # The self-test setup passes `excluded_files` to scan.
                    # The scan logic should ideally not create transactions for explicitly excluded files.
                    # If it does, execution should skip them.
                    pass # This needs refinement based on actual scan behavior for excluded files.
            elif tx["STATUS"] not in [TransactionStatus.COMPLETED.value, TransactionStatus.SKIPPED.value]:
                all_completed_or_skipped = False
                print(f"FAIL: Transaction {tx['id']} (Type: {tx['TYPE']}, Path: {tx['PATH']}) has status {tx['STATUS']}.")
                break
        check(all_completed_or_skipped, "All processed transactions are COMPLETED or SKIPPED.",
              "Not all processed transactions are COMPLETED or SKIPPED.")
    else:
        check(False, "", f"Could not load transaction file {original_transaction_file} for status verification.")

    print(f"--- Self-Test Verification Summary: {passed_checks} PASSED, {failed_checks} FAILED ---")
    if failed_checks > 0:
        raise AssertionError(f"Self-test failed with {failed_checks} assertion(s).")
    return True


@flow(name="Self-Test Flow", log_prints=True)
def self_test_flow(
    temp_dir_str: str,
    dry_run_for_test: bool,
    process_binary_for_test: bool # This arg might become less relevant if binary processing is simplified
) -> None:
    temp_dir = Path(temp_dir_str)
    _create_self_test_environment(temp_dir)

    # Self-test specific parameters
    test_excluded_dirs: List[str] = [] 
    test_excluded_files: List[str] = ["exclude_this_flojoy_file.txt"]
    # File extensions to scan for content (example)
    test_extensions = [".txt", ".py", ".md"] 

    transaction_file = temp_dir / SELF_TEST_PRIMARY_TRANSACTION_FILE

    print("Self-Test: Scanning directory...")
    transactions = scan_directory_for_occurrences(
        root_dir=temp_dir,
        excluded_dirs=test_excluded_dirs,
        excluded_files=test_excluded_files,
        file_extensions=test_extensions,
        process_binary_files=process_binary_for_test # Script now only handles text-like
    )
    save_transactions(transactions, transaction_file)
    print(f"Self-Test: Scan complete. {len(transactions)} transactions planned in {transaction_file}")

    if not dry_run_for_test:
        print("Self-Test: Executing transactions...")
        execution_stats = execute_all_transactions(
            transactions_file_path=transaction_file,
            root_dir=temp_dir,
            dry_run=False, # Actual execution for self-test verification
            resume=False   # Start fresh for self-test
        )
        print(f"Self-Test: Execution complete. Stats: {execution_stats}")
        
        _verify_self_test_results_task(
            temp_dir=temp_dir,
            original_transaction_file=transaction_file
        )
    else:
        print("Self-Test: Dry run selected. Skipping execution and verification of changes.")
        # Optionally, could do a dry-run execution and inspect the transaction file for proposed changes.
        # For now, dry-run self-test mainly checks scan and setup.


# --- Main CLI Orchestration ---
@flow(name="Mass Find and Replace Orchestration Flow", log_prints=True)
def main_flow(
    directory: str,
    extensions: Optional[List[str]],
    exclude_dirs: List[str],
    exclude_files: List[str],
    process_binary_files: bool, # Note: new logic is less focused on binary
    dry_run: bool,
    skip_scan: bool,
    resume: bool,
    force_execution: bool # For skipping prompt
):
    root_dir = Path(directory).resolve()
    if not root_dir.is_dir():
        print(f"Error: Root directory '{root_dir}' does not exist or is not a directory.")
        return

    transaction_json_path = root_dir / MAIN_TRANSACTION_FILE_NAME

    if not dry_run and not force_execution and not resume: # Prompt only for fresh, non-dry runs
        print("--- Proposed Operation ---")
        print(f"Root Directory: {root_dir}")
        print("Operation: Replace 'flojoy' and its variants with 'atlasvibe' equivalents.")
        print(f"File Extensions for content scan: {extensions if extensions else 'All non-binary (heuristic)'}")
        print(f"Exclude Dirs: {exclude_dirs}")
        print(f"Exclude Files: {exclude_files}")
        # print(f"Process Binary Files: {process_binary_files}") # Less relevant now
        print("-------------------------")
        confirm = input("Proceed with these changes? (yes/no): ")
        if confirm.lower() != 'yes':
            print("Operation cancelled by user.")
            return

    if not skip_scan and not resume: # Scan only if not skipping and not resuming (resume implies transactions exist)
        print(f"Starting scan phase in '{root_dir}'...")
        found_transactions = scan_directory_for_occurrences(
            root_dir=root_dir,
            excluded_dirs=exclude_dirs,
            excluded_files=exclude_files,
            file_extensions=extensions,
            process_binary_files=process_binary_files
        )
        save_transactions(found_transactions, transaction_json_path)
        print(f"Scan complete. {len(found_transactions)} transactions planned in '{transaction_json_path}'")
        if not found_transactions:
            print("No occurrences found. Nothing to do.")
            return
    elif not transaction_json_path.exists() and (skip_scan or resume):
        print(f"Error: --skip-scan or --resume was used, but '{transaction_json_path}' not found.")
        return
    else:
        print(f"Using existing transaction file: '{transaction_json_path}'.")

    if dry_run:
        print("Dry run: Simulating execution of transactions...")
        # For dry run, we can load and display transactions, or simulate execution without changes
        # The execute_all_transactions function handles dry_run internally.
        stats = execute_all_transactions(
            transactions_file_path=transaction_json_path,
            root_dir=root_dir,
            dry_run=True,
            resume=resume # Resume can be true for a dry run to see what would be resumed
        )
        print(f"Dry run complete. Simulated stats: {stats}")
        print(f"Review '{transaction_json_path}' for transaction details and statuses (will show DRY_RUN).")
    else:
        print("Starting execution phase...")
        stats = execute_all_transactions(
            transactions_file_path=transaction_json_path,
            root_dir=root_dir,
            dry_run=False,
            resume=resume
        )
        print(f"Execution phase complete. Stats: {stats}")
        print(f"Review '{transaction_json_path}' for a log of applied changes and their statuses.")


def main_cli() -> None:
    # Simplified parser for "flojoy" -> "atlasvibe" specific task
    parser = argparse.ArgumentParser(
        description="Find and replace 'flojoy' with 'atlasvibe' (case-preserving) in file/folder names and content.",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument("directory", nargs='?', default=".",
                        help="The root directory to process (default: current directory).")
    parser.add_argument("--extensions", nargs="+",
                        help="List of file extensions to process for content changes (e.g., .py .txt). If not specified, attempts to process text-like files.")
    parser.add_argument("--exclude-dirs", nargs="+", default=[".git", ".venv", "node_modules", "__pycache__"],
                        help="Directory names to exclude (default: .git, .venv, node_modules, __pycache__).")
    parser.add_argument("--exclude-files", nargs="+", default=[],
                        help="Specific file paths (relative to root) to exclude.")
    # process_binary_files is less relevant as the core logic is text-based.
    # Kept for compatibility but its effect is now minor.
    parser.add_argument("--process-binary-files", action="store_true",
                        help="Attempt to scan files that seem binary. Replacement is still text-based. (Use with caution)")
    parser.add_argument("--dry-run", action="store_true",
                        help="Scan and plan changes, but do not execute them. Updates transaction file with DRY_RUN status.")
    parser.add_argument("--skip-scan", action="store_true",
                        help=f"Skip scan phase; use existing '{MAIN_TRANSACTION_FILE_NAME}'.")
    parser.add_argument("--resume", action="store_true",
                        help=f"Resume execution from existing '{MAIN_TRANSACTION_FILE_NAME}', processing PENDING or IN_PROGRESS tasks.")
    parser.add_argument("--force", "--yes", "-y", action="store_true",
                        help="Force execution without confirmation prompt (if not in dry-run or resume mode).")
    parser.add_argument("--self-test", action="store_true",
                        help="Run a predefined self-test in a temporary directory.")

    args = parser.parse_args()
    
    # Remove the monkeypatching for _get_case_preserved_replacement from main_cli
    # The trace prints are now directly in the function if needed for debugging.

    if args.self_test:
        print("Running self-test...")
        with tempfile.TemporaryDirectory(prefix="mass_replace_self_test_") as tmpdir_str:
            try:
                # For self-test, we don't use Prefect's task/flow decorators from the main script's context
                # but call the underlying functions directly or a specific self-test flow.
                # The self_test_flow is already decorated with @flow if PREFECT_AVAILABLE.
                self_test_flow(
                    temp_dir_str=tmpdir_str,
                    dry_run_for_test=args.dry_run,
                    process_binary_for_test=args.process_binary_files
                )
                if not args.dry_run:
                     print("Self-test PASSED.")
                else:
                     print("Self-test dry run scan complete.")
            except AssertionError as e:
                print(f"Self-test FAILED: {e}")
                sys.exit(1)
            except Exception as e:
                print(f"Self-test ERRORED: {e}")
                # import traceback
                # traceback.print_exc() # For more detailed error during self-test
                sys.exit(1)
        return

    # Default transaction log files to always exclude from main operations
    default_log_files_to_exclude = [
        MAIN_TRANSACTION_FILE_NAME,
        MAIN_TRANSACTION_FILE_NAME + TRANSACTION_FILE_BACKUP_EXT,
    ]
    for log_file in default_log_files_to_exclude:
        if log_file not in args.exclude_files:
            args.exclude_files.append(log_file)
    
    # Script self-exclusion (if script is in target directory)
    try:
        script_path_obj = Path(__file__).resolve(strict=True)
        target_dir_resolved = Path(args.directory).resolve(strict=True)
        if script_path_obj.is_relative_to(target_dir_resolved):
             script_relative_to_target = str(script_path_obj.relative_to(target_dir_resolved))
             if script_relative_to_target not in args.exclude_files:
                 args.exclude_files.append(script_relative_to_target)
    except (FileNotFoundError, ValueError):
         pass # Silently skip if paths can't be resolved or script not in target.

    main_flow(
        directory=args.directory,
        extensions=args.extensions,
        exclude_dirs=args.exclude_dirs,
        exclude_files=args.exclude_files,
        process_binary_files=args.process_binary_files,
        dry_run=args.dry_run,
        skip_scan=args.skip_scan,
        resume=args.resume,
        force_execution=args.force
    )

if __name__ == "__main__":
    try:
        main_cli()
    except ImportError as e:
        if "prefect" in str(e).lower():
            print("Warning: Prefect not installed, running without Prefect task/flow features.")
            # Potentially call a non-Prefect version of main_flow or ensure functions work standalone
            # For now, the dummy decorators handle this.
            main_cli() # Try again, dummy decorators should be in place
        else:
            print(f"Critical dependency missing: {e}")
            sys.exit(1)
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        # import traceback
        # traceback.print_exc() # For debugging
        sys.exit(1)

